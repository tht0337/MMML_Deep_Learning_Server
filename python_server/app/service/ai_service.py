import os
import csv
import pandas as pd
from python_server.app.dto.category_dto import CategoryUpdateReq
from python_server.app.ml_training.user_finetune import (
    save_user_feedback,
    run_finetune,
    LOG_PATH,   # ê¸°ì¡´ í•™ìŠµ ë°ì´í„° ê²½ë¡œ
)
import torch
from python_server.app.config.category_config import CategoryConfig
from python_server.app.ml_training.train_gru import BiGRUTextClassifier

# =========================================
# ê²½ë¡œ ì„¤ì • (í•­ìƒ python_server/app ê¸°ì¤€ìœ¼ë¡œ ê³ ì •)
# =========================================

APP_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
PROJECT_ROOT = os.path.dirname(APP_DIR)

ML_TRAINING_DIR = os.path.join(APP_DIR, "ml_training")
USER_DIR = os.path.join(ML_TRAINING_DIR, "user_data")
# user_data = app/ml_training/user_data
CSV_PATH = os.path.join(USER_DIR, "correction_log.csv")
print("ğŸ“ USER_DIR:", USER_DIR)
print("ğŸ“ CSV_PATH:", CSV_PATH)
# user_data í´ë” ìë™ ìƒì„±
os.makedirs(USER_DIR, exist_ok=True)


# =========================================
# 1. ì‚¬ìš©ì í”¼ë“œë°± ì €ì¥
# =========================================
def save_user_feedback_service(req: CategoryUpdateReq):
    """
    ìœ ì €ê°€ ìˆ˜ì •í•œ ì¹´í…Œê³ ë¦¬ ì •ë³´ë¥¼ CSVì— append ì €ì¥
    """
    # correction_log.csvê°€ ì²˜ìŒ ìƒì„±ë˜ëŠ” ê²½ìš° í—¤ë” ì¶”ê°€
    write_header = not os.path.exists(CSV_PATH)

    with open(CSV_PATH, mode="a", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)

        # ì²« ìƒì„± ì‹œ í—¤ë” ì‘ì„±
        if write_header:
            writer.writerow(["placeOfUse", "entryAmount", "memo", "category", "occurredAt"])

        # ë°ì´í„° ì¶”ê°€
        writer.writerow([
            req.placeOfUse,
            req.entryAmount,
            req.memo,
            req.category,
            req.occurredAt
        ])

    return {"status": "saved", "data": req.model_dump()}


# =========================================
# 2. Fine-tune ì¤€ë¹„ ì—¬ë¶€ í™•ì¸
# =========================================
def check_finetune_ready_service():
    """
    ìœ ì € CSV ë˜ëŠ” ê¸°ì¡´ ë¡œê·¸ CSVì—ì„œ ë°ì´í„° ê°œìˆ˜ í™•ì¸
    """
    if not os.path.exists(CSV_PATH):
        return {"count": 0, "ready": False}

    df = pd.read_csv(CSV_PATH, encoding="utf-8-sig")
    count = len(df)

    return {
        "count": count,
        "ready": count >= 20  # ì¡°ê±´: 20ê±´ ì´ìƒì´ë©´ ë  ìˆ˜ ìˆìŒ
    }


# =========================================
# 3. Fine-tune ì‹¤í–‰
# =========================================
def run_finetune_service():
    """
    ì‹¤ì œ fine-tune ì‹¤í–‰
    """
    try:
        run_finetune()  # ì™¸ë¶€ í•¨ìˆ˜ í˜¸ì¶œ
        return {"status": "ok", "msg": "fine-tune completed"}
    except Exception as e:
        return {"status": "error", "msg": str(e)}

MAX_LEN = 20

def encode_chars(text, char_to_idx):
    if not text or str(text).lower() == "nan":
        text = "<EMPTY>"

    ids = [char_to_idx.get(ch, 0) for ch in text[:MAX_LEN]]
    while len(ids) < MAX_LEN:
        ids.append(0)

    return torch.tensor([ids], dtype=torch.long)


def predict(price, merchant, memo=""):

    # 1ï¸âƒ£ ë£° ê¸°ë°˜ ë¨¼ì € ì²˜ë¦¬
    rule = CategoryConfig.rule_based(merchant, memo)
    if rule is not None:
        return rule

    # 2ï¸âƒ£ ëª¨ë¸ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
    BASE_DIR = os.path.dirname(
        os.path.dirname(os.path.abspath(__file__))  # service/ ì—ì„œ í•œ ë‹¨ê³„ ìœ„ë¡œ
    )
    MODEL_DIR = os.path.join(BASE_DIR, "ml_training", "model")

    MODEL_PATH = os.path.join(MODEL_DIR, "char_gru_classifier.pth")
    ENC_PATH = os.path.join(MODEL_DIR, "char_gru_encoders.pth")

    enc = torch.load(ENC_PATH, map_location="cpu", weights_only=False)
    char_to_idx = enc["char_to_idx"]
    category_encoder = enc["category_encoder"]

    price_tensor = torch.tensor([[price / 100000]], dtype=torch.float32)
    merchant_tensor = encode_chars(merchant, char_to_idx)
    memo_tensor = encode_chars(memo, char_to_idx)

    vocab_size = len(char_to_idx)
    num_classes = len(category_encoder.classes_)

    model = BiGRUTextClassifier(vocab_size, num_classes)
    model.load_state_dict(torch.load(MODEL_PATH, map_location="cpu"))
    model.eval()

    with torch.no_grad():
        output = model(price_tensor, merchant_tensor, memo_tensor)
        pred_idx = torch.argmax(output, dim=1).item()

    return category_encoder.inverse_transform([pred_idx])[0]