import os
import csv
import pandas as pd
import torch
import torch.nn as nn

from datetime import datetime
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from torch.utils.data import DataLoader

from python_server.app.config.category_config import CategoryConfig
from python_server.app.ml_training.train_gru import BiGRUTextClassifier, TransactionDataset

# =========================================
# ğŸ“Œ PATH
# =========================================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
USER_DATA_DIR = os.path.join(BASE_DIR, "user_data")
MODEL_DIR = os.path.join(BASE_DIR, "model")

os.makedirs(USER_DATA_DIR, exist_ok=True)
os.makedirs(MODEL_DIR, exist_ok=True)

LOG_PATH = os.path.join(USER_DATA_DIR, "correction_log.csv")

# =========================================
# ğŸ“Œ Fine-Tune ìƒíƒœ ì €ì¥ (FastAPIì—ì„œ ì¡°íšŒ ê°€ëŠ¥)
# idle / running / success / fail
# =========================================
FINE_TUNE_STATUS = {
    "status": "idle",
    "message": None,
    "timestamp": None
}

# =========================================
# ğŸ“Œ ì‚¬ìš©ì í”¼ë“œë°± ì €ì¥ (CSV append)
# =========================================
def save_user_feedback(merchant, price, memo, category):
    row = {
        "placeOfUse": merchant,
        "entryAmount": price,
        "memo": memo,
        "category": category,
        "timestamp": datetime.now().isoformat()
    }

    file_exists = os.path.exists(LOG_PATH)

    with open(LOG_PATH, "a", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, fieldnames=row.keys())
        if not file_exists:
            writer.writeheader()
        writer.writerow(row)

    print(f"ğŸ“ ì‚¬ìš©ì ìˆ˜ì • ì €ì¥: {row}")


# =========================================
# ğŸ“Œ ì‚¬ìš©ì ë°ì´í„° ë¡œë“œ + ê¸°ì¡´ í•™ìŠµë°ì´í„° ë³‘í•©
# =========================================
def load_user_finetune_dataset(original_df):
    if not os.path.exists(LOG_PATH):
        print("âš  ì‚¬ìš©ì ìˆ˜ì • ë°ì´í„° ì—†ìŒ â†’ ê¸°ë³¸ ë°ì´í„°ë¡œ í•™ìŠµ")
        return original_df

    user_df = pd.read_csv(LOG_PATH, encoding="utf-8-sig")
    print(f"ğŸ”„ ì‚¬ìš©ì ë°ì´í„° {len(user_df)}ê°œ ë³‘í•©")

    merged = pd.concat([original_df, user_df], ignore_index=True)
    return merged


# =========================================
# ğŸ“Œ Fine-Tune ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œì—ì„œ ëŒë¦´ ë¡œì§)
# =========================================
def run_finetune():
    print("\nğŸ”¥ [Fine-tune] ì‚¬ìš©ì ê¸°ë°˜ ì¬í•™ìŠµ ì‹œì‘")
    FINE_TUNE_STATUS["status"] = "running"
    FINE_TUNE_STATUS["timestamp"] = datetime.now().isoformat()
    FINE_TUNE_STATUS["message"] = "í•™ìŠµ ì¤‘..."

    try:
        # -------------------------
        # 1) ê¸°ì¡´ í•™ìŠµ ë°ì´í„° ë¡œë“œ
        # -------------------------
        original_path = os.path.join(BASE_DIR, "data", "combined_train.csv")
        print(original_path)

        if not os.path.exists(original_path):
            raise Exception("ê¸°ì¡´ í•™ìŠµ ë°ì´í„° combined_train.csv ì—†ìŒ")

        df = pd.read_csv(original_path, encoding="utf-8-sig")
        print(f"ğŸ“Œ ê¸°ì¡´ í•™ìŠµ ë°ì´í„°: {len(df)}í–‰")

        # -------------------------
        # 2) ì‚¬ìš©ì ë°ì´í„° ë³‘í•©
        # -------------------------
        df = load_user_finetune_dataset(df)
        print(f"ğŸ“Œ ì „ì²´ í•™ìŠµ ë°ì´í„°: {len(df)}í–‰")

        # -------------------------
        # 3) ì¹¼ëŸ¼ëª… í†µì¼
        # ê¸°ì¡´ ë°ì´í„°ê°€ merchant/priceì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ rename
        # -------------------------
        rename_map = {
            "merchant": "placeOfUse",
            "price": "entryAmount"
        }
        df = df.rename(columns=rename_map)

        required_cols = ["placeOfUse", "entryAmount", "memo", "category"]
        for col in required_cols:
            if col not in df.columns:
                raise Exception(f"Fine-tune ë¶ˆê°€: '{col}' ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")

        # -------------------------
        # 4) ë¼ë²¨ ì¸ì½”ë” ìƒì„±
        # -------------------------
        category_encoder = LabelEncoder()
        category_encoder.fit(CategoryConfig.CATEGORIES)

        # -------------------------
        # 5) ë¬¸ì ì¸ë±ìŠ¤ ìƒì„±
        # -------------------------
        chars = set()
        for t in df["placeOfUse"].astype(str).tolist() + df["memo"].astype(str).tolist():
            for ch in t:
                chars.add(ch)

        char_list = sorted(list(chars))
        char_to_idx = {ch: i+1 for i, ch in enumerate(char_list)}
        char_to_idx["<EMPTY>"] = 0

        vocab_size = len(char_to_idx)
        num_classes = len(category_encoder.classes_)

        # -------------------------
        # 6) Train/Test split
        # -------------------------
        train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)
        train_dataset = TransactionDataset(train_df, category_encoder, char_to_idx)
        train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)

        # -------------------------
        # 7) ëª¨ë¸ ë¡œë“œ
        # -------------------------
        model_path = os.path.join(MODEL_DIR, "char_gru_classifier.pth")
        model = BiGRUTextClassifier(vocab_size, num_classes)

        try:
            if os.path.exists(model_path):
                state_dict = torch.load(model_path, map_location="cpu")
                model.load_state_dict(state_dict)
                print("ğŸ“¥ ê¸°ì¡´ ëª¨ë¸ ë¶ˆëŸ¬ì˜´")
        except:
            print("âš  ê¸°ì¡´ ëª¨ë¸ êµ¬ì¡° ë¶ˆì¼ì¹˜ â†’ ìƒˆ ëª¨ë¸ í•™ìŠµ")

        # -------------------------
        # 8) Fine-Tune í•™ìŠµLoop
        # -------------------------
        model.train()
        opt = torch.optim.Adam(model.parameters(), lr=0.0005)
        loss_fn = nn.CrossEntropyLoss()

        print("ğŸ”¥ Fine-tune í•™ìŠµ ì‹œì‘")

        for epoch in range(6):
            total_loss = 0
            for price, merchant, memo, label in train_loader:
                opt.zero_grad()
                pred = model(price, merchant, memo)
                loss = loss_fn(pred, label)
                loss.backward()
                opt.step()
                total_loss += loss.item()

            print(f"[Epoch {epoch+1}] Loss: {total_loss:.4f}")

        # -------------------------
        # 9) ëª¨ë¸ ì €ì¥
        # -------------------------
        torch.save(model.state_dict(), model_path)
        torch.save({
            "category_encoder": category_encoder,
            "char_to_idx": char_to_idx,
        }, os.path.join(MODEL_DIR, "char_gru_encoders.pth"))

        print("ğŸ‰ Fine-tune ì™„ë£Œ & ëª¨ë¸ ì—…ë°ì´íŠ¸ë¨")

        # ì„±ê³µ ìƒíƒœ ì €ì¥
        FINE_TUNE_STATUS["status"] = "success"
        FINE_TUNE_STATUS["message"] = "í•™ìŠµ ì™„ë£Œ"

        return True

    except Exception as e:
        print("âŒ Fine-Tune ì‹¤íŒ¨:", str(e))

        FINE_TUNE_STATUS["status"] = "fail"
        FINE_TUNE_STATUS["message"] = str(e)

        return False
