import os
import pandas as pd
import csv
import torch
import torch.nn as nn
from sklearn.preprocessing import LabelEncoder
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
from datetime import datetime

from python_server.app.config.category_config import CategoryConfig
from python_server.app.ml_training.train_gru import BiGRUTextClassifier, TransactionDataset


BASE_DIR = os.path.dirname(os.path.abspath(__file__))
USER_DATA_DIR = os.path.join(BASE_DIR, "user_data")
MODEL_DIR = os.path.join(BASE_DIR, "model")

os.makedirs(USER_DATA_DIR, exist_ok=True)
os.makedirs(MODEL_DIR, exist_ok=True)

LOG_PATH = os.path.join(USER_DATA_DIR, "correction_log.csv")

# ================ ë°ì´í„°ì…‹ ì„¸ì´ë¸Œ ================
def save_user_feedback(merchant: str, price: int, memo: str, category: str):
    """
    ì‚¬ìš©ì ì¹´í…Œê³ ë¦¬ ìˆ˜ì • ë°ì´í„°ë¥¼ correction_log.csvì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜
    - merchant : ê°€ë§¹ì ëª…
    - price    : ê°€ê²©(ì •ìˆ˜)
    - memo     : ë©”ëª¨/ìƒì„¸ë‚´ìš©
    - category : ì‚¬ìš©ìê°€ ì§ì ‘ ì„ íƒí•œ ì¹´í…Œê³ ë¦¬
    """

    row = {
        "merchant": merchant,
        "price": price,
        "memo": memo,
        "category": category,
        "timestamp": datetime.now().isoformat()
    }

    file_exists = os.path.exists(LOG_PATH)

    with open(LOG_PATH, "a", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, fieldnames=row.keys())

        # ì²« ì €ì¥ ì‹œ header ìƒì„±
        if not file_exists:
            writer.writeheader()

        writer.writerow(row)

    print(f"ğŸ“ ì €ì¥ë¨ â†’ {row}")
    return True
# ================ ë°ì´í„°ì…‹ ë¡œë” (ê¸°ì¡´ train_gru ì½”ë“œ ì¬ì‚¬ìš©) ================
def load_user_finetune_dataset(original_df):
    """ê¸°ì¡´ í•™ìŠµ ë°ì´í„°(original_df)ì— correction_log.csv ë³‘í•©"""

    if not os.path.exists(LOG_PATH):
        print("âš  ì‚¬ìš©ì ìˆ˜ì • ë°ì´í„° ì—†ìŒ. ê¸°ë³¸ ëª¨ë¸ ìœ ì§€.")
        return original_df

    user_df = pd.read_csv(LOG_PATH, encoding="utf-8-sig")
    print(f"ğŸ”„ ì‚¬ìš©ì ë°ì´í„° {len(user_df)}ê°œ ë³‘í•©")

    merged = pd.concat([original_df, user_df], ignore_index=True)
    return merged


# ================ ì‹¤ì œ ë¯¸ì„¸í•™ìŠµ ë¡œì§ ================
def run_finetune():
    print("\nğŸ”¥ [Fine-tune] ì‚¬ìš©ì ë°ì´í„° ê¸°ë°˜ ì¬í•™ìŠµ ì‹œì‘")

    # 1) ê¸°ì¡´ í•™ìŠµë°ì´í„° ë¡œë“œ
    original_path = os.path.join(BASE_DIR, "data", "combined_train.csv")
    if not os.path.exists(original_path):
        raise Exception("âŒ ê¸°ì¡´ í•™ìŠµ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: combined_train.csv")

    df = pd.read_csv(original_path, encoding="utf-8-sig")
    print(f"ğŸ“Œ ê¸°ì¡´ í•™ìŠµ ë°ì´í„°: {len(df)}í–‰")

    # 2) ì‚¬ìš©ì ìˆ˜ì •ë°ì´í„° ë³‘í•©
    df = load_user_finetune_dataset(df)
    print(f"ğŸ“Œ ë³‘í•©ëœ ì „ì²´ ë°ì´í„°: {len(df)}í–‰")

    # 3) ë¼ë²¨/ë¬¸ì ì¸ì½”ë” ìƒì„±
    category_encoder = LabelEncoder()
    category_encoder.fit(CategoryConfig.CATEGORIES)

    # ë¬¸ì ì¸ë±ì‹±
    chars = set()
    for t in df["merchant"].astype(str).tolist() + df["memo"].astype(str).tolist():
        for ch in t:
            chars.add(ch)

    char_list = sorted(list(chars))
    char_to_idx = {ch: i+1 for i, ch in enumerate(char_list)}
    char_to_idx["<EMPTY>"] = 0

    vocab_size = len(char_to_idx)
    num_classes = len(category_encoder.classes_)

    # 4) ë°ì´í„° split
    train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)
    train_dataset = TransactionDataset(train_df, category_encoder, char_to_idx)
    train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)

    # 5) ëª¨ë¸ ë¡œë“œ í›„ ì¬í•™ìŠµ
    model_path = os.path.join(MODEL_DIR, "char_gru_classifier.pth")
    model = BiGRUTextClassifier(vocab_size, num_classes)

    if os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path, map_location="cpu"))
        print("ğŸ“¥ ê¸°ì¡´ ëª¨ë¸ ë¶ˆëŸ¬ì˜´")

    model.train()
    opt = torch.optim.Adam(model.parameters(), lr=0.0005)
    loss_fn = nn.CrossEntropyLoss()

    print("ğŸ”¥ Fine-tune í•™ìŠµ ì‹œì‘")

    for epoch in range(6):  # ì‚¬ìš©ì ë°ì´í„°ëŠ” ì ìœ¼ë‹ˆ ì ë‹¹í•œ Epoch
        total_loss = 0
        for price, merchant, memo, label in train_loader:
            opt.zero_grad()
            pred = model(price, merchant, memo)
            loss = loss_fn(pred, label)
            loss.backward()
            opt.step()
            total_loss += loss.item()

        print(f"[Epoch {epoch+1}] Loss: {total_loss:.4f}")

    # 6) ëª¨ë¸ ì €ì¥
    torch.save(model.state_dict(), model_path)
    torch.save({
        "category_encoder": category_encoder,
        "char_to_idx": char_to_idx,
    }, os.path.join(MODEL_DIR, "char_gru_encoders.pth"))

    print("ğŸ‰ Fine-tune ì™„ë£Œ & ëª¨ë¸ ì—…ë°ì´íŠ¸ë¨")

    return True
